{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN1az1VH82um"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Monday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unNwfcZr82uo"
      },
      "source": [
        "# Question 1 (25 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "\n",
        "(3) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(4) Collect all the information of the 904 narrators in the Densho Digital Repository.\n",
        "\n",
        "(5)**Collect a total of 10000 reviews** of the top 100 most popular software from G2 and Capterra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ayZdiNqP82uo",
        "outputId": "8a6f3874-e11b-4899-fcb8-e37a5469daa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Word_Count\n",
            "0  Keanu gets pissed and shoots people in the fac...          12\n",
            "1  Kinetic, concise, and stylish; John Wick kicks...           8\n",
            "2      Story: 3 minutes; Entertainment: 101 minutes.           6\n",
            "3                        Yeah I'm Thinking He's Back           5\n",
            "4  The best action revenge film of all time from ...          12\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "# Base IMDb URL for reviews\n",
        "base_url = \"https://www.imdb.com/title/tt2911666/reviews/?ref_=ttrt_sa_3\"\n",
        "\n",
        "# Headers to mimic a real user browser and avoid blocks\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# Function to scrape IMDb reviews\n",
        "def scrape_imdb_reviews(num_reviews=100):\n",
        "    reviews_data = []\n",
        "    page = 1\n",
        "\n",
        "    while len(reviews_data) < num_reviews:\n",
        "        try:\n",
        "            # Construct the URL for pagination\n",
        "            url = f\"{base_url}?start={(page - 1) * 10}\"\n",
        "\n",
        "            # Send a request to IMDb\n",
        "            response = requests.get(url, headers=HEADERS)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"Failed to fetch page {page}. Status Code: {response.status_code}\")\n",
        "                break\n",
        "\n",
        "            # Parse the page content\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Find all review elements\n",
        "            review_blocks = soup.find_all('h3', class_='ipc-title__text')\n",
        "\n",
        "            # If no reviews are found, stop the loop\n",
        "            if not review_blocks:\n",
        "                print(\"No more reviews found. IMDb may have changed the structure.\")\n",
        "                break\n",
        "\n",
        "            # Extract and store reviews\n",
        "            for review in review_blocks:\n",
        "                review_text = review.text.strip()\n",
        "                reviews_data.append({\"Review\": review_text})\n",
        "\n",
        "                # Stop if we reach the required number of reviews\n",
        "                if len(reviews_data) >= num_reviews:\n",
        "                    break\n",
        "\n",
        "            page += 1  # Move to the next page\n",
        "            time.sleep(1)  # Delay to avoid being blocked\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping page {page}: {e}\")\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(reviews_data)\n",
        "\n",
        "# Scrape 100 reviews (adjust as needed)\n",
        "df = scrape_imdb_reviews(100)\n",
        "\n",
        "# Add a word count column\n",
        "df[\"Word_Count\"] = df[\"Review\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"John_Wick_4_Reviews.csv\", index=False)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req = requests.get(base_url)\n",
        "print(req.text)  # Check if IMDb is returning the expected HTML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCRxw9SFJzdL",
        "outputId": "70eb7594-8531-4ee8-e4b3-9b1ee485eb76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\r\n",
            "<head><title>403 Forbidden</title></head>\r\n",
            "<body>\r\n",
            "<center><h1>403 Forbidden</h1></center>\r\n",
            "</body>\r\n",
            "</html>\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kZMkU0a282up",
        "outputId": "a3045864-8b57-4fa5-bdbc-e72e4df61417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzWYr5t682up",
        "outputId": "2be7d92f-a2c5-4aff-e0ff-ec133965e2f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       Imagine a video game where you are shooting ba...\n",
              "1       The Table, the international crminal brotherho...\n",
              "2       The first three John Wick films came in fairly...\n",
              "3       These John Wick movies can be sort of fun in t...\n",
              "4       I went to the cinema with great expectations. ...\n",
              "                              ...                        \n",
              "1245    HORRIBLE movie. I love John Wick. I mean I wou...\n",
              "1246    In a world where movie sequels seem to be loat...\n",
              "1247    May or may not count as a spoiler but John Wic...\n",
              "1248    Indiana jones, terminator, predator, Jurassic ...\n",
              "1249    John Wick: Chapter 4 is almost three hours of ...\n",
              "Name: Reviews, Length: 1250, dtype: object"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Reviews\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5naIRmGi82up"
      },
      "outputs": [],
      "source": [
        "# Assuming your DataFrame is named 'df'\n",
        "df[\"Review\"].to_csv(\"John Wick_Chapter 4_reviews.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": true,
        "id": "bGk82-1p82up",
        "outputId": "f1d3580a-85b8-47d9-af59-7e5e3489d1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review\n",
              "0  Keanu gets pissed and shoots people in the fac...\n",
              "1  Kinetic, concise, and stylish; John Wick kicks...\n",
              "2      Story: 3 minutes; Entertainment: 101 minutes.\n",
              "3                        Yeah I'm Thinking He's Back\n",
              "4  The best action revenge film of all time from ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63f00aeb-1be0-48fd-a0ab-094d469ba2f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keanu gets pissed and shoots people in the fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kinetic, concise, and stylish; John Wick kicks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Story: 3 minutes; Entertainment: 101 minutes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah I'm Thinking He's Back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best action revenge film of all time from ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f00aeb-1be0-48fd-a0ab-094d469ba2f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63f00aeb-1be0-48fd-a0ab-094d469ba2f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63f00aeb-1be0-48fd-a0ab-094d469ba2f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20e416cf-3185-41d5-a577-d52aa50c7d1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20e416cf-3185-41d5-a577-d52aa50c7d1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20e416cf-3185-41d5-a577-d52aa50c7d1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"I'm Thinking I'm Back\",\n          \"More from this title\",\n          \"I Don't Get It\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df1 = pd.read_csv(\"John Wick_Chapter 4_reviews.csv\")\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eUKPIQYN82uq",
        "outputId": "011c2146-a0e4-44db-abe7-cfd9943066b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "# Question 2 (15 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nkflduEz82uq"
      },
      "outputs": [],
      "source": [
        "# Set options to display full column content\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNC0prQJ-uN",
        "outputId": "52730557-670b-474b-8557-b2f5122a2aab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Load the CSV file\n",
        "# Read the CSV file containing the movie reviews into a DataFrame\n",
        "df1 = pd.read_csv(\"John Wick_Chapter 4_reviews.csv\")\n",
        "\n",
        "# Function to preprocess and clean review\n",
        "def review_preprocessing(review):\n",
        "    # Remove punctuation and special characters\n",
        "    review = ''.join([character for character in review if character not in string.punctuation])\n",
        "\n",
        "    # Remove numbers\n",
        "    review = ''.join([character for character in review if not character.isdigit()])\n",
        "\n",
        "    # Tokenize the review\n",
        "    words = nltk.word_tokenize(review)\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [w for w in words if w.lower() not in stopwords.words('english')]\n",
        "\n",
        "    # Lowercase all words\n",
        "    words = [w.lower() for w in words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(w) for w in words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "    # Join the words back into a cleaned sentence\n",
        "    cleaned_user_reviews = ' '.join(words)\n",
        "\n",
        "    return cleaned_user_reviews\n",
        "\n",
        "# Apply the preprocessing function to the \"Reviews\" column and create a new column\n",
        "# Create a new column in the DataFrame containing the cleaned and preprocessed reviews\n",
        "df1['Reviews_After_Cleaning'] = df1['Review'].apply(review_preprocessing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "b1OxvHLC82uq",
        "outputId": "9c9ebfbe-2ac8-426b-a4a2-31c3eed9e457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                             Review  \\\n",
              "0  Keanu gets pissed and shoots people in the face for 101 minutes*   \n",
              "1               Kinetic, concise, and stylish; John Wick kicks ass.   \n",
              "2                     Story: 3 minutes; Entertainment: 101 minutes.   \n",
              "3                                       Yeah I'm Thinking He's Back   \n",
              "4        The best action revenge film of all time from 2014 so far!   \n",
              "\n",
              "                   Reviews_After_Cleaning  \n",
              "0   keanu get piss shoot peopl face minut  \n",
              "1  kinet concis stylish john wick kick as  \n",
              "2             stori minut entertain minut  \n",
              "3                   yeah im think he back  \n",
              "4        best action reveng film time far  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-683b4a72-b1b8-43ef-8e00-3fa6c273e5f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Reviews_After_Cleaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keanu gets pissed and shoots people in the face for 101 minutes*</td>\n",
              "      <td>keanu get piss shoot peopl face minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kinetic, concise, and stylish; John Wick kicks ass.</td>\n",
              "      <td>kinet concis stylish john wick kick as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Story: 3 minutes; Entertainment: 101 minutes.</td>\n",
              "      <td>stori minut entertain minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah I'm Thinking He's Back</td>\n",
              "      <td>yeah im think he back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best action revenge film of all time from 2014 so far!</td>\n",
              "      <td>best action reveng film time far</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-683b4a72-b1b8-43ef-8e00-3fa6c273e5f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-683b4a72-b1b8-43ef-8e00-3fa6c273e5f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-683b4a72-b1b8-43ef-8e00-3fa6c273e5f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5171b7c4-01ea-452a-b984-735adf7bf563\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5171b7c4-01ea-452a-b984-735adf7bf563')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5171b7c4-01ea-452a-b984-735adf7bf563 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"I'm Thinking I'm Back\",\n          \"More from this title\",\n          \"I Don't Get It\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reviews_After_Cleaning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"im think im back\",\n          \"titl\",\n          \"dont get\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a7w3J1fL82uq",
        "outputId": "36604da8-35ff-42a0-9395-0c6842dc9bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         keanu get piss shoot peopl face minut\n",
            "1        kinet concis stylish john wick kick as\n",
            "2                   stori minut entertain minut\n",
            "3                         yeah im think he back\n",
            "4              best action reveng film time far\n",
            "                        ...                    \n",
            "95                                             \n",
            "96                                        excel\n",
            "97             dont mess anoth person dog simpl\n",
            "98                   love movi highli recommend\n",
            "99    keanu bring quiet believ action throwback\n",
            "Name: Reviews_After_Cleaning, Length: 100, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df1[\"Reviews_After_Cleaning\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wV37DFk-82uq"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to a new CSV file with the cleaned data\n",
        "df1.to_csv(\"Cleaned_text_of_John Wick_Chapter 4_reviews.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Save the cleaned DataFrame to a CSV file\n",
        "cleaned_file_Johnwick = \"Cleaned_text_of_JohnWick_Chapter4_reviews.csv\"\n",
        "df.to_csv(cleaned_file_Johnwick, index=False)\n",
        "\n",
        "files.download(cleaned_file_Johnwick)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ii58yggbPGp7",
        "outputId": "c30b3386-2f5b-4507-ef8d-3258f193da4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e137ce12-19e6-43bb-be7b-c27ae8a20cc8\", \"Cleaned_text_of_JohnWick_Chapter4_reviews.csv\", 3957)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "# Question 3 (15 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KpZ3xVi882ur",
        "outputId": "efe78556-5871-47e9-eec6-06531c655ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                             Review  \\\n",
              "0  Keanu gets pissed and shoots people in the face for 101 minutes*   \n",
              "1               Kinetic, concise, and stylish; John Wick kicks ass.   \n",
              "2                     Story: 3 minutes; Entertainment: 101 minutes.   \n",
              "3                                       Yeah I'm Thinking He's Back   \n",
              "4        The best action revenge film of all time from 2014 so far!   \n",
              "\n",
              "                   Reviews_After_Cleaning  \n",
              "0   keanu get piss shoot peopl face minut  \n",
              "1  kinet concis stylish john wick kick as  \n",
              "2             stori minut entertain minut  \n",
              "3                   yeah im think he back  \n",
              "4        best action reveng film time far  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76df820e-39b7-4b5e-b2d4-2c6a4f2d5e17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Reviews_After_Cleaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keanu gets pissed and shoots people in the face for 101 minutes*</td>\n",
              "      <td>keanu get piss shoot peopl face minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kinetic, concise, and stylish; John Wick kicks ass.</td>\n",
              "      <td>kinet concis stylish john wick kick as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Story: 3 minutes; Entertainment: 101 minutes.</td>\n",
              "      <td>stori minut entertain minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah I'm Thinking He's Back</td>\n",
              "      <td>yeah im think he back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best action revenge film of all time from 2014 so far!</td>\n",
              "      <td>best action reveng film time far</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76df820e-39b7-4b5e-b2d4-2c6a4f2d5e17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76df820e-39b7-4b5e-b2d4-2c6a4f2d5e17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76df820e-39b7-4b5e-b2d4-2c6a4f2d5e17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d207020-5f84-42ae-b818-7e53309e9c0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d207020-5f84-42ae-b818-7e53309e9c0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d207020-5f84-42ae-b818-7e53309e9c0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"I'm Thinking I'm Back\",\n          \"More from this title\",\n          \"I Don't Get It\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reviews_After_Cleaning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"im think im back\",\n          \"titl\",\n          \"dont get\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aMlJBNiN82ur",
        "outputId": "56975663-d516-488f-e73a-84ca7a445c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "s3Wy8_ZP82ur",
        "outputId": "f7e1a7c8-1d91-4bbb-da11-ec9524a294a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         keanu get piss shoot peopl face minut\n",
              "1        kinet concis stylish john wick kick as\n",
              "2                   stori minut entertain minut\n",
              "3                         yeah im think he back\n",
              "4              best action reveng film time far\n",
              "                        ...                    \n",
              "95                                             \n",
              "96                                        excel\n",
              "97             dont mess anoth person dog simpl\n",
              "98                   love movi highli recommend\n",
              "99    keanu bring quiet believ action throwback\n",
              "Name: Reviews_After_Cleaning, Length: 100, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews_After_Cleaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>keanu get piss shoot peopl face minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kinet concis stylish john wick kick as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stori minut entertain minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yeah im think he back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best action reveng film time far</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>excel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>dont mess anoth person dog simpl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>love movi highli recommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>keanu bring quiet believ action throwback</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df1[\"Reviews_After_Cleaning\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Vk8WdsKPxQ",
        "outputId": "c8f22997-9270-4be6-bc7e-0c95efcb164a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tree import Tree\n"
      ],
      "metadata": {
        "id": "GSVcAOeRKS8X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Gnhg_jUZ82ur",
        "outputId": "fe71bdac-9296-4431-e8a5-1d665bf88668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis for review 1:\n",
            "Tags:\n",
            "[('keanu', 'NN'), ('get', 'VB'), ('piss', 'JJ'), ('shoot', 'NN'), ('peopl', 'NN'), ('face', 'NN'), ('minut', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "           S                                                  \n",
            "           |                                                   \n",
            "         CLAUSE                                               \n",
            "    _______|___________________                                \n",
            "   |                           VP                             \n",
            "   |        ___________________|_________________________      \n",
            "   NP      |             NP             NP       NP      NP   \n",
            "   |       |        _____|_____         |        |       |     \n",
            "keanu/NN get/VB piss/JJ     shoot/NN peopl/NN face/NN minut/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S keanu/NN get/VB piss/JJ shoot/NN peopl/NN face/NN minut/NN)\n",
            "==================================================\n",
            "Analysis for review 2:\n",
            "Tags:\n",
            "[('kinet', 'NN'), ('concis', 'NN'), ('stylish', 'JJ'), ('john', 'NN'), ('wick', 'NN'), ('kick', 'NN'), ('as', 'IN')]\n",
            "Constituency Parsing Tree:\n",
            "                             S                                 \n",
            "   __________________________|_____________________________     \n",
            "  |      NP        NP                NP            NP      NP  \n",
            "  |      |         |          _______|_____        |       |    \n",
            "as/IN kinet/NN concis/NN stylish/JJ     john/NN wick/NN kick/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S kinet/NN concis/NN stylish/JJ john/NN wick/NN kick/NN as/IN)\n",
            "==================================================\n",
            "Analysis for review 3:\n",
            "Tags:\n",
            "[('stori', 'JJ'), ('minut', 'NN'), ('entertain', 'NN'), ('minut', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "                S                          \n",
            "           _____|_____________________      \n",
            "          NP               NP         NP   \n",
            "    ______|_____           |          |     \n",
            "stori/JJ     minut/NN entertain/NN minut/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S stori/JJ minut/NN entertain/NN minut/NN)\n",
            "==================================================\n",
            "Analysis for review 4:\n",
            "Tags:\n",
            "[('yeah', 'RB'), ('im', 'JJ'), ('think', 'NN'), ('he', 'PRP'), ('back', 'RB')]\n",
            "Constituency Parsing Tree:\n",
            "                  S                      \n",
            "    ______________|___________            \n",
            "   |      |       |           NP         \n",
            "   |      |       |       ____|_____      \n",
            "yeah/RB he/PRP back/RB im/JJ     think/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S yeah/RB im/JJ think/NN he/PRP back/RB)\n",
            "==================================================\n",
            "Analysis for review 5:\n",
            "Tags:\n",
            "[('best', 'JJS'), ('action', 'NN'), ('reveng', 'NN'), ('film', 'NN'), ('time', 'NN'), ('far', 'RB')]\n",
            "Constituency Parsing Tree:\n",
            "                    S                              \n",
            "    ________________|__________________________     \n",
            "   |       |        NP        NP       NP      NP  \n",
            "   |       |        |         |        |       |    \n",
            "best/JJS far/RB action/NN reveng/NN film/NN time/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S best/JJS action/NN reveng/NN film/NN time/NN far/RB)\n",
            "==================================================\n",
            "Analysis for review 6:\n",
            "Tags:\n",
            "[('deliv', 'NN'), ('taken', 'VBN')]\n",
            "Constituency Parsing Tree:\n",
            "           S          \n",
            "     ______|_____      \n",
            "    |            NP   \n",
            "    |            |     \n",
            "taken/VBN     deliv/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S deliv/NN taken/VBN)\n",
            "==================================================\n",
            "Analysis for review 7:\n",
            "Tags:\n",
            "[('manli', 'JJ'), ('action', 'NN'), ('film', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "                 S            \n",
            "           ______|________     \n",
            "          NP              NP  \n",
            "    ______|______         |    \n",
            "manli/JJ     action/NN film/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S manli/JJ action/NN film/NN)\n",
            "==================================================\n",
            "Analysis for review 8:\n",
            "Tags:\n",
            "[('coolest', 'JJS'), ('action', 'NN'), ('film', 'NN'), ('youll', 'NN'), ('see', 'VBP'), ('year', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "                         S                                \n",
            "      ___________________|________________                 \n",
            "     |          |        |              CLAUSE            \n",
            "     |          |        |        ________|_____           \n",
            "     |          |        |       |              VP        \n",
            "     |          |        |       |         _____|_____     \n",
            "     |          NP       NP      NP       |           NP  \n",
            "     |          |        |       |        |           |    \n",
            "coolest/JJS action/NN film/NN youll/NN see/VBP     year/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S coolest/JJS action/NN film/NN youll/NN see/VBP year/NN)\n",
            "==================================================\n",
            "Analysis for review 9:\n",
            "Tags:\n",
            "[('dont', 'NN'), ('get', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "         S        \n",
            "    _____|____     \n",
            "   NP         NP  \n",
            "   |          |    \n",
            "dont/NN     get/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S dont/NN get/NN)\n",
            "==================================================\n",
            "Analysis for review 10:\n",
            "Tags:\n",
            "[('im', 'NN'), ('think', 'VBP'), ('im', 'NN'), ('back', 'RB')]\n",
            "Constituency Parsing Tree:\n",
            "             S               \n",
            "     ________|____________    \n",
            "    |        |      NP    NP \n",
            "    |        |      |     |   \n",
            "think/VBP back/RB im/NN im/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S im/NN think/VBP im/NN back/RB)\n",
            "==================================================\n",
            "Analysis for review 11:\n",
            "Tags:\n",
            "[('violent', 'JJ'), ('grip', 'NN'), ('stori', 'NN'), ('plenti', 'NN'), ('unstop', 'JJ'), ('action', 'NN'), ('shootout', 'NN'), ('breathtak', 'NN'), ('fight', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "                                              S                                                    \n",
            "             _________________________________|_______________________________________________      \n",
            "            NP            NP        NP               NP                NP          NP         NP   \n",
            "     _______|_____        |         |          ______|______           |           |          |     \n",
            "violent/JJ     grip/NN stori/NN plenti/NN unstop/JJ     action/NN shootout/NN breathtak/NN fight/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S\n",
            "  violent/JJ\n",
            "  grip/NN\n",
            "  stori/NN\n",
            "  plenti/NN\n",
            "  unstop/JJ\n",
            "  action/NN\n",
            "  shootout/NN\n",
            "  breathtak/NN\n",
            "  fight/NN)\n",
            "==================================================\n",
            "Analysis for review 12:\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Tags:\n",
            "[]\n",
            "Constituency Parsing Tree:\n",
            " S \n",
            " |  \n",
            "...\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S )\n",
            "==================================================\n",
            "Analysis for review 13:\n",
            "Tags:\n",
            "[('excel', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "   S    \n",
            "   |     \n",
            "   NP   \n",
            "   |     \n",
            "excel/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S excel/NN)\n",
            "==================================================\n",
            "Analysis for review 14:\n",
            "Tags:\n",
            "[('dont', 'NN'), ('mess', 'NN'), ('anoth', 'DT'), ('person', 'NN'), ('dog', 'NN'), ('simpl', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "                   S                                  \n",
            "    _______________|_____________________________      \n",
            "   NP      NP             NP             NP      NP   \n",
            "   |       |        ______|______        |       |     \n",
            "dont/NN mess/NN anoth/DT     person/NN dog/NN simpl/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S dont/NN mess/NN anoth/DT person/NN dog/NN simpl/NN)\n",
            "==================================================\n",
            "Analysis for review 15:\n",
            "Tags:\n",
            "[('love', 'VB'), ('movi', 'NN'), ('highli', 'NN'), ('recommend', 'NN')]\n",
            "Constituency Parsing Tree:\n",
            "           S                          \n",
            "           |                           \n",
            "           VP                         \n",
            "    _______|___________________        \n",
            "   |       NP       NP         NP     \n",
            "   |       |        |          |       \n",
            "love/VB movi/NN highli/NN recommend/NN\n",
            "\n",
            "None\n",
            "Named Entities:\n",
            "(S love/VB movi/NN highli/NN recommend/NN)\n",
            "==================================================\n",
            "Total Nouns (N): 45\n",
            "Total Verbs (V): 5\n",
            "Total Adjectives (Adj): 9\n",
            "Total Adverbs (Adv): 4\n",
            "Entity Counts:\n",
            "Person: 0\n",
            "Organization: 0\n",
            "Location: 0\n",
            "Product: 0\n",
            "Date: 0\n"
          ]
        }
      ],
      "source": [
        "# \"Reviews_After_Cleaning\" column\n",
        "cleaned_review = df1[\"Reviews_After_Cleaning\"]\n",
        "\n",
        "# Define a simple elements for constituency parsing\n",
        "elements = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}  # Noun\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+$}  # Verb\n",
        "    PP: {<IN><NP>}  # Prepositional\n",
        "    CLAUSE: {<NP><VP>}  # Clause\n",
        "\"\"\"\n",
        "\n",
        "# Function to conduct syntax and structure analysis\n",
        "def perform_syntax_structure_analysis(review):\n",
        "    # Tokenize the review into words\n",
        "    words = nltk.word_tokenize(review)\n",
        "\n",
        "    tags = nltk.pos_tag(words)\n",
        "    parser = nltk.RegexpParser(elements)\n",
        "    constituency_tree = parser.parse(tags)\n",
        "\n",
        "    named_entities = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(review)))\n",
        "\n",
        "    return tags, constituency_tree, named_entities\n",
        "\n",
        "# Initialize counters for POS categories\n",
        "total_nouns = 0\n",
        "total_verbs = 0\n",
        "total_adjectives = 0\n",
        "total_adverbs = 0\n",
        "\n",
        "# Initialize dictionaries to count entities\n",
        "entity_counts = {\n",
        "    \"Person\": 0,\n",
        "    \"Organization\": 0,\n",
        "    \"Location\": 0,\n",
        "    \"Product\": 0,\n",
        "    \"Date\": 0\n",
        "}\n",
        "\n",
        "# Here we are performing syntax and structure analysis for each review in the column\n",
        "for indexs, review in enumerate(cleaned_review[:15], start=1):\n",
        "    print(f\"Analysis for review {indexs}:\")\n",
        "    tags, constituency_tree, named_entities = perform_syntax_structure_analysis(review)\n",
        "\n",
        "    # Calculate the total number of Nouns (N), Verbs (V), Adjectives (Adj), and Adverbs (Adv) for each review\n",
        "    nouns = sum(1 for word, pos in tags if pos.startswith('N'))\n",
        "    verbs = sum(1 for word, pos in tags if pos.startswith('V'))\n",
        "    adjectives = sum(1 for word, pos in tags if pos.startswith('J'))\n",
        "    adverbs = sum(1 for word, pos in tags if pos.startswith('R'))\n",
        "\n",
        "    total_nouns += nouns\n",
        "    total_verbs += verbs\n",
        "    total_adjectives += adjectives\n",
        "    total_adverbs += adverbs\n",
        "\n",
        "    # Extract entities and count them\n",
        "    for entity in named_entities:\n",
        "        if isinstance(entity, nltk.Tree):\n",
        "            entity_label = entity.label()\n",
        "            entity_text = \" \".join(word for word, pos in entity.leaves())\n",
        "            if entity_label in entity_counts:\n",
        "                entity_counts[entity_label] += 1\n",
        "\n",
        "    print(\"Tags:\")\n",
        "    print(tags)\n",
        "\n",
        "    print(\"Constituency Parsing Tree:\")\n",
        "    print(Tree.fromstring(str(constituency_tree)).pretty_print())\n",
        "\n",
        "    print(\"Named Entities:\")\n",
        "    print(named_entities)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Print the totals\n",
        "print(f\"Total Nouns (N): {total_nouns}\")\n",
        "print(f\"Total Verbs (V): {total_verbs}\")\n",
        "print(f\"Total Adjectives (Adj): {total_adjectives}\")\n",
        "print(f\"Total Adverbs (Adv): {total_adverbs}\")\n",
        "\n",
        "# Print entity counts\n",
        "print(\"Entity Counts:\")\n",
        "for entity_type, count in entity_counts.items():\n",
        "    print(f\"{entity_type}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EvQyroxB82ur",
        "outputId": "f69b79ad-2013-496b-cd73-733ebace5079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Nouns: 5\n",
            "Number of Verbs: 1\n",
            "Number of Adjectives: 1\n",
            "Number of Adverbs: 0\n",
            "Constituency Parsing Tree:\n",
            "                               S                              \n",
            "   ____________________________|_________________________      \n",
            "  |       NP             NP             NP       NP      NP   \n",
            "  |       |         _____|_____         |        |       |     \n",
            "get/VB keanu/NN piss/JJ     shoot/NN peopl/NN face/NN minut/NN\n",
            "\n",
            "\n",
            "Named Entity Recognition (NER):\n"
          ]
        }
      ],
      "source": [
        "#alternative\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tree import ParentedTree\n",
        "import string\n",
        "\n",
        "# Load the English language model in spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# review text\n",
        "review_text = df1[\"Reviews_After_Cleaning\"].iloc[0]\n",
        "\n",
        "#Parts of Speech (POS) Tagging\n",
        "doc = nlp(review_text)\n",
        "noun_count = 0\n",
        "verb_count = 0\n",
        "adj_count = 0\n",
        "adv_count = 0\n",
        "\n",
        "for token in doc:\n",
        "    if token.pos_ == 'NOUN':\n",
        "        noun_count += 1\n",
        "    elif token.pos_ == 'VERB':\n",
        "        verb_count += 1\n",
        "    elif token.pos_ == 'ADJ':\n",
        "        adj_count += 1\n",
        "    elif token.pos_ == 'ADV':\n",
        "        adv_count += 1\n",
        "\n",
        "print(f\"Number of Nouns: {noun_count}\")\n",
        "print(f\"Number of Verbs: {verb_count}\")\n",
        "print(f\"Number of Adjectives: {adj_count}\")\n",
        "print(f\"Number of Adverbs: {adv_count}\")\n",
        "\n",
        "#Constituency Parsing\n",
        "def nltk_constituency_parsing(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    for sentence in sentences:\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        tagged = nltk.pos_tag(words)\n",
        "        grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "        cp = nltk.RegexpParser(grammar)\n",
        "        tree = cp.parse(tagged)\n",
        "        print(\"Constituency Parsing Tree:\")\n",
        "        tree.pretty_print()\n",
        "\n",
        "# Call the constituency parsing function on the review  text\n",
        "nltk_constituency_parsing(review_text)\n",
        "\n",
        "#Named Entity Recognition\n",
        "entities = {}\n",
        "for entity in doc.ents:\n",
        "    entities[entity.label_] = entities.get(entity.label_, 0) + 1\n",
        "\n",
        "print(\"\\nNamed Entity Recognition (NER):\")\n",
        "for label, count in entities.items():\n",
        "    print(f\"{label}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeFlfaoJ82ur"
      },
      "source": [
        "# **Following Questions must answer using AI assitance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxu7jFez82ur"
      },
      "source": [
        "#Question 4 (20 points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUlbq5AX82ur"
      },
      "source": [
        "Q4. (PART-1)\n",
        "Web scraping data from the GitHub Marketplace to gather details about popular actions. Using Python, the process begins by sending HTTP requests to multiple pages of the marketplace (1000 products), handling pagination through dynamic page numbers. The key details extracted include the product name, a short description, and the URL.\n",
        "\n",
        " The extracted data is stored in a structured CSV format with columns for product name, description, URL, and page number. A time delay is introduced between requests to avoid server overload. ChatGPT can assist by helping with the parsing of HTML, error handling, and generating reports based on the data collected.\n",
        "\n",
        " The goal is to complete the scraping within a specified time limit, ensuring that the process is efficient and adheres to GitHub’s usage guidelines.\n",
        "\n",
        "(PART -2)\n",
        "\n",
        "1.   **Preprocess Data**: Clean the text by tokenizing, removing stopwords, and converting to lowercase.\n",
        "\n",
        "2. Perform **Data Quality** operations.\n",
        "\n",
        "\n",
        "Preprocessing:\n",
        "Preprocessing involves cleaning the text by removing noise such as special characters, HTML tags, and unnecessary whitespace. It also includes tasks like tokenization, stopword removal, and lemmatization to standardize the text for analysis.\n",
        "\n",
        "Data Quality:\n",
        "Data quality checks ensure completeness, consistency, and accuracy by verifying that all required columns are filled and formatted correctly. Additionally, it involves identifying and removing duplicates, handling missing values, and ensuring the data reflects the true content accurately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J6IuVOY82ur"
      },
      "source": [
        "Github MarketPlace page:\n",
        "https://github.com/marketplace?type=actions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "def scrape_github_marketplace_actions(\n",
        "    start_page=1,\n",
        "    end_page=50,    # <-- 50 pages * 20 items/page = 1000 items\n",
        "    delay=1.0,\n",
        "    output_file='github_actions_1000.csv'\n",
        "):\n",
        "    \"\"\"\n",
        "    Scrapes GitHub Marketplace Actions listings from start_page to end_page.\n",
        "    Each page contains around 20 products, so 50 pages ~ 1000 products.\n",
        "\n",
        "    :param start_page: The first page number to scrape\n",
        "    :param end_page: The last page number to scrape\n",
        "    :param delay: Delay (seconds) between requests to avoid overloading the server\n",
        "    :param output_file: CSV file to write the results\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/108.0.0.0 Safari/537.36\"\n",
        "        ),\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
        "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    }\n",
        "\n",
        "    # Potential CSS selectors (change if needed by inspecting actual HTML)\n",
        "    possible_selectors = [\n",
        "        \"article.py-4.border-bottom\",\n",
        "        \"div.col-12.d-flex.flex-wrap.py-4.border-bottom.color-border-muted\",\n",
        "        \"li.Box-row\",\n",
        "        \"div[class*='marketplace-item']\"\n",
        "    ]\n",
        "\n",
        "    fieldnames = ['product_name', 'description', 'url', 'page']\n",
        "\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for page_num in range(start_page, end_page + 1):\n",
        "            # Marketplace Actions URL, changing the 'page' parameter\n",
        "            url = f\"https://github.com/marketplace/actions?page={page_num}\"\n",
        "            print(f\"Scraping page {page_num}: {url}\")\n",
        "\n",
        "            # Make the request\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, timeout=10)\n",
        "                response.raise_for_status()\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Request error on page {page_num}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Parse with BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Try each selector until we find one that matches items\n",
        "            action_cards = []\n",
        "            for selector in possible_selectors:\n",
        "                test_cards = soup.select(selector)\n",
        "                if test_cards:\n",
        "                    action_cards = test_cards\n",
        "                    print(f\"  Found {len(action_cards)} items using selector: {selector}\")\n",
        "                    break\n",
        "            else:\n",
        "                # If no selector matched\n",
        "                print(\"  No items found with any known selector on this page.\")\n",
        "                # Optional: print snippet of HTML for debugging\n",
        "                continue\n",
        "\n",
        "            # Extract product details\n",
        "            for card in action_cards:\n",
        "                name_tag = card.find('h3')\n",
        "                desc_tag = card.find('p')\n",
        "                link_tag = card.find('a', href=True)\n",
        "\n",
        "                if not (name_tag and link_tag):\n",
        "                    continue\n",
        "\n",
        "                product_name = name_tag.get_text(strip=True)\n",
        "                description = desc_tag.get_text(strip=True) if desc_tag else \"\"\n",
        "                action_url = link_tag['href']\n",
        "                if action_url.startswith('/'):\n",
        "                    action_url = \"https://github.com\" + action_url\n",
        "\n",
        "                writer.writerow({\n",
        "                    'product_name': product_name,\n",
        "                    'description': description,\n",
        "                    'url': action_url,\n",
        "                    'page': page_num\n",
        "                })\n",
        "\n",
        "            # Small delay between pages\n",
        "            time.sleep(delay)\n",
        "\n",
        "    print(f\"Scraping completed. Data saved to '{output_file}'.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Scrape pages 1 through 50 (~1000 products) with a 1-second delay\n",
        "    scrape_github_marketplace_actions(start_page=1, end_page=50, delay=1.0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cJaPnA4KtbZ",
        "outputId": "249053d8-d55b-4c96-8b5e-4d37fc0c5651"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1: https://github.com/marketplace/actions?page=1\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 2: https://github.com/marketplace/actions?page=2\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 3: https://github.com/marketplace/actions?page=3\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 4: https://github.com/marketplace/actions?page=4\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 5: https://github.com/marketplace/actions?page=5\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 6: https://github.com/marketplace/actions?page=6\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 7: https://github.com/marketplace/actions?page=7\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 8: https://github.com/marketplace/actions?page=8\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 9: https://github.com/marketplace/actions?page=9\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 10: https://github.com/marketplace/actions?page=10\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 11: https://github.com/marketplace/actions?page=11\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 12: https://github.com/marketplace/actions?page=12\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 13: https://github.com/marketplace/actions?page=13\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 14: https://github.com/marketplace/actions?page=14\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 15: https://github.com/marketplace/actions?page=15\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 16: https://github.com/marketplace/actions?page=16\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 17: https://github.com/marketplace/actions?page=17\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 18: https://github.com/marketplace/actions?page=18\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 19: https://github.com/marketplace/actions?page=19\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 20: https://github.com/marketplace/actions?page=20\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 21: https://github.com/marketplace/actions?page=21\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 22: https://github.com/marketplace/actions?page=22\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 23: https://github.com/marketplace/actions?page=23\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 24: https://github.com/marketplace/actions?page=24\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 25: https://github.com/marketplace/actions?page=25\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 26: https://github.com/marketplace/actions?page=26\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 27: https://github.com/marketplace/actions?page=27\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 28: https://github.com/marketplace/actions?page=28\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 29: https://github.com/marketplace/actions?page=29\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 30: https://github.com/marketplace/actions?page=30\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 31: https://github.com/marketplace/actions?page=31\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 32: https://github.com/marketplace/actions?page=32\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 33: https://github.com/marketplace/actions?page=33\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 34: https://github.com/marketplace/actions?page=34\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 35: https://github.com/marketplace/actions?page=35\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 36: https://github.com/marketplace/actions?page=36\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 37: https://github.com/marketplace/actions?page=37\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 38: https://github.com/marketplace/actions?page=38\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 39: https://github.com/marketplace/actions?page=39\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 40: https://github.com/marketplace/actions?page=40\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 41: https://github.com/marketplace/actions?page=41\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 42: https://github.com/marketplace/actions?page=42\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 43: https://github.com/marketplace/actions?page=43\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 44: https://github.com/marketplace/actions?page=44\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 45: https://github.com/marketplace/actions?page=45\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 46: https://github.com/marketplace/actions?page=46\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 47: https://github.com/marketplace/actions?page=47\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 48: https://github.com/marketplace/actions?page=48\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 49: https://github.com/marketplace/actions?page=49\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping page 50: https://github.com/marketplace/actions?page=50\n",
            "  Found 20 items using selector: div[class*='marketplace-item']\n",
            "Scraping completed. Data saved to 'github_actions_1000.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_csv_with_pandas(csv_file='github_actions_1000.csv'):\n",
        "    \"\"\"Reads and displays rows from the CSV using pandas.\"\"\"\n",
        "    df = pd.read_csv(csv_file)\n",
        "    print(df)  # Print the entire DataFrame\n",
        "    print(\"\\nDataFrame shape:\", df.shape)  # (num_rows, num_columns)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    read_csv_with_pandas()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmyE3Gdj6FJ_",
        "outputId": "b4bebb6d-fe32-4c60-8576-338007432209"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     product_name  \\\n",
            "0                  TruffleHog OSS   \n",
            "1                   Metrics embed   \n",
            "2    yq - portable yaml processor   \n",
            "3                    Super-Linter   \n",
            "4          Gosec Security Checker   \n",
            "..                            ...   \n",
            "995               Rebuild Armbian   \n",
            "996                 GitHub Script   \n",
            "997        Deploy to GitHub Pages   \n",
            "998          ChatGPT CodeReviewer   \n",
            "999                    FTP Deploy   \n",
            "\n",
            "                                           description  \\\n",
            "0                  Scan Github Actions with TruffleHog   \n",
            "1    An infographics generator with 40+ plugins and...   \n",
            "2    create, read, update, delete, merge, validate ...   \n",
            "3    Super-linter is a ready-to-run collection of l...   \n",
            "4                      Runs the gosec security checker   \n",
            "..                                                 ...   \n",
            "995                                Build Armbian Linux   \n",
            "996         Run simple scripts using the GitHub client   \n",
            "997  This action will handle the deployment process...   \n",
            "998            A Code Review Action Powered By ChatGPT   \n",
            "999  Automate deploying websites and more with this...   \n",
            "\n",
            "                                                   url  page  \n",
            "0    https://github.com/marketplace/actions/truffle...     1  \n",
            "1    https://github.com/marketplace/actions/metrics...     1  \n",
            "2    https://github.com/marketplace/actions/yq-port...     1  \n",
            "3    https://github.com/marketplace/actions/super-l...     1  \n",
            "4    https://github.com/marketplace/actions/gosec-s...     1  \n",
            "..                                                 ...   ...  \n",
            "995  https://github.com/marketplace/actions/rebuild...    50  \n",
            "996  https://github.com/marketplace/actions/github-...    50  \n",
            "997  https://github.com/marketplace/actions/deploy-...    50  \n",
            "998  https://github.com/marketplace/actions/chatgpt...    50  \n",
            "999  https://github.com/marketplace/actions/ftp-deploy    50  \n",
            "\n",
            "[1000 rows x 4 columns]\n",
            "\n",
            "DataFrame shape: (1000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqCp8rfN-VK-",
        "outputId": "d1353b21-538d-48b2-da57-d703b65c5923"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bjdluSZFKmL",
        "outputId": "a3f9dccb-1113-4706-b7f6-382e20e58523"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import time\n",
        "\n",
        "# If you're in Google Colab, import this module to enable file download:\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean text by removing HTML tags, special chars, converting to lowercase,\n",
        "    tokenizing, removing stopwords, and lemmatizing.\n",
        "    \"\"\"\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove non-alphanumeric (preserve space)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "\n",
        "    # Join tokens back into a single string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def preprocess_and_download(input_csv='github_actions_1000.csv', output_csv='github_actions_cleaned.csv'):\n",
        "    # 1) Load the data\n",
        "    df = pd.read_csv(input_csv)\n",
        "    print(f\"Initial dataset shape: {df.shape}\")\n",
        "\n",
        "    # 2) Basic data checks\n",
        "    print(\"\\nHEAD of the original data:\")\n",
        "    print(df.head(3))\n",
        "\n",
        "    # 3) Remove duplicates\n",
        "    before = len(df)\n",
        "    df.drop_duplicates(subset=['product_name', 'description', 'url', 'page'], inplace=True)\n",
        "    after = len(df)\n",
        "    print(f\"\\nRemoved {before - after} duplicates. Current shape: {df.shape}\")\n",
        "\n",
        "    # 4) Handle missing values\n",
        "    #    Replace empty strings with NaN so we can drop them easily\n",
        "    df['product_name'] = df['product_name'].replace('', np.nan)\n",
        "    df['description'] = df['description'].replace('', np.nan)\n",
        "\n",
        "    # Drop rows missing product_name or description\n",
        "    before = len(df)\n",
        "    df.dropna(subset=['product_name', 'description'], how='any', inplace=True)\n",
        "    after = len(df)\n",
        "    print(f\"Dropped {before - after} rows with missing product_name/description. Shape: {df.shape}\")\n",
        "\n",
        "    # If 'page' is missing, fill with 0\n",
        "    if 'page' in df.columns:\n",
        "        df['page'] = df['page'].fillna(0)\n",
        "\n",
        "    # 5) Preprocess text columns\n",
        "    start_time = time.time()\n",
        "    df['cleaned_product_name'] = df['product_name'].apply(clean_text)\n",
        "    df['cleaned_description']  = df['description'].apply(clean_text)\n",
        "    end_time = time.time()\n",
        "    print(f\"\\nText cleaning took {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # 6) Show a sample of the cleaned data\n",
        "    print(\"\\nHEAD of cleaned data:\")\n",
        "    print(df[['product_name', 'cleaned_product_name', 'description', 'cleaned_description']].head(3))\n",
        "\n",
        "    # 7) Save to CSV\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\nCleaned data saved to: {output_csv} - Final shape: {df.shape}\")\n",
        "\n",
        "    # 8) Download the file if in Google Colab\n",
        "    if IN_COLAB:\n",
        "        print(\"\\nDownloading the cleaned file to your local machine...\")\n",
        "        files.download(output_csv)\n",
        "\n",
        "preprocess_and_download('github_actions_1000.csv', 'github_actions_cleaned.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "C1KlSE8x6MjC",
        "outputId": "3c4b0205-0824-4a87-9ef6-e942f1eec55d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (1000, 4)\n",
            "\n",
            "HEAD of the original data:\n",
            "                   product_name  \\\n",
            "0                TruffleHog OSS   \n",
            "1                 Metrics embed   \n",
            "2  yq - portable yaml processor   \n",
            "\n",
            "                                         description  \\\n",
            "0                Scan Github Actions with TruffleHog   \n",
            "1  An infographics generator with 40+ plugins and...   \n",
            "2  create, read, update, delete, merge, validate ...   \n",
            "\n",
            "                                                 url  page  \n",
            "0  https://github.com/marketplace/actions/truffle...     1  \n",
            "1  https://github.com/marketplace/actions/metrics...     1  \n",
            "2  https://github.com/marketplace/actions/yq-port...     1  \n",
            "\n",
            "Removed 0 duplicates. Current shape: (1000, 4)\n",
            "Dropped 0 rows with missing product_name/description. Shape: (1000, 4)\n",
            "\n",
            "Text cleaning took 4.30 seconds.\n",
            "\n",
            "HEAD of cleaned data:\n",
            "                   product_name        cleaned_product_name  \\\n",
            "0                TruffleHog OSS               trufflehog os   \n",
            "1                 Metrics embed                metric embed   \n",
            "2  yq - portable yaml processor  yq portable yaml processor   \n",
            "\n",
            "                                         description  \\\n",
            "0                Scan Github Actions with TruffleHog   \n",
            "1  An infographics generator with 40+ plugins and...   \n",
            "2  create, read, update, delete, merge, validate ...   \n",
            "\n",
            "                                 cleaned_description  \n",
            "0                      scan github action trufflehog  \n",
            "1  infographics generator 40 plugins 300 option d...  \n",
            "2      create read update delete merge validate yaml  \n",
            "\n",
            "Cleaned data saved to: github_actions_cleaned.csv - Final shape: (1000, 6)\n",
            "\n",
            "Downloading the cleaned file to your local machine...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25f75ee2-1927-49a4-bf53-8e6ad7d1d7a7\", \"github_actions_cleaned.csv\", 211945)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "250uSfXa82ur"
      },
      "source": [
        "#Question 5 (20 points)\n",
        "\n",
        "PART 1:\n",
        "Web Scrape  tweets from Twitter using the Tweepy API, specifically targeting hashtags related to subtopics (machine learning or artificial intelligence.)\n",
        "The extracted data includes the tweet ID, username, and text.\n",
        "\n",
        "Part 2:\n",
        "Perform data cleaning procedures\n",
        "\n",
        "A final data quality check ensures the completeness and consistency of the dataset. The cleaned data is then saved into a CSV file for further analysis.\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1.   Follow tutorials provided in canvas to obtain api keys. Use ChatGPT to get the code. Make sure the file is downloaded and saved.\n",
        "2.   Make sure you divide GPT code as shown in tutorials, dont make multiple requestes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# 🔹 Step 1: Twitter API Credentials\n",
        "API_KEY = \"4W8I4MqXHtaxqdhphMeUMAfjY\"\n",
        "API_SECRET = \"oKe4Evosm83e8D7tPbn1npsztebxjZMa3p00OsRWUd8lJTJoI5\"\n",
        "ACCESS_TOKEN = \"1891605471368445957-sQp17BnPeOcusJNZrnLPGlasneyerm\"\n",
        "ACCESS_SECRET = \"nn4dB3dXZ9orWmYkjuNPV38LVc7Uzip8QaWaB5aY3lgsi\"\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAP9fzQEAAAAALfJohZT1hMgc2rw9uoNXo6RJb5U%3DRMSVdGVZi91u4MLcC1n23HKHIrHuKGsT0uLEUFFFgt7kzLDK9Y\"\n",
        "\n",
        "# 🔹 Step 2: Authenticate with Twitter API\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "# 🔹 Step 3: Define the Search Query\n",
        "query = \"#MachineLearning OR #ArtificialIntelligence OR #AI -is:retweet lang:en\"\n",
        "\n",
        "# 🔹 Step 4: Fetch Tweets\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=[\"id\", \"text\", \"author_id\", \"created_at\"], max_results=100)\n",
        "\n",
        "# 🔹 Step 5: Extract Data\n",
        "tweet_data = []\n",
        "\n",
        "if tweets.data:\n",
        "    for tweet in tweets.data:\n",
        "        tweet_data.append({\n",
        "            \"Tweet_ID\": tweet.id,\n",
        "            \"Username\": f\"user_{tweet.author_id}\",  # Usernames require an additional API call\n",
        "            \"Created_At\": tweet.created_at,\n",
        "            \"Text\": tweet.text\n",
        "        })\n",
        "\n",
        "# 🔹 Step 6: Convert to DataFrame\n",
        "df = pd.DataFrame(tweet_data)\n",
        "\n",
        "# 🔹 Step 7: Data Cleaning Function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove mentions\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)  # Remove hashtags\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)  # Remove special characters\n",
        "    return text.strip()\n",
        "\n",
        "df[\"Cleaned_Text\"] = df[\"Text\"].apply(clean_text)\n",
        "\n",
        "# 🔹 Step 8: Data Quality Check\n",
        "df.drop_duplicates(subset=[\"Tweet_ID\"], keep=\"first\", inplace=True)  # Remove duplicate tweets\n",
        "df.dropna(inplace=True)  # Remove missing values\n",
        "\n",
        "# 🔹 Step 9: Save to CSV\n",
        "df.to_csv(\"twitter_ai_ml_tweets.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\" Data scraping and cleaning complete! File saved: twitter_ai_ml_tweets.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5iI30fq55by",
        "outputId": "4c777e4e-615e-46ad-ee64-685bd5db9aa5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data scraping and cleaning complete! File saved: twitter_ai_ml_tweets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"twitter_ai_ml_tweets.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YF7YFWC8GUgd",
        "outputId": "4bfdc59f-0eea-4e88-b46d-af587a737806"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa1fd4ca-26cb-433e-9212-033fa0081763\", \"twitter_ai_ml_tweets.csv\", 33500)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded file\n",
        "file_path = \"twitter_ai_ml_tweets.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "df.info(), df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hA0lTBn6-0P",
        "outputId": "d400c449-db5f-428b-bcc0-7cc3c9760594"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Tweet_ID      100 non-null    int64 \n",
            " 1   Username      100 non-null    object\n",
            " 2   Created_At    100 non-null    object\n",
            " 3   Text          100 non-null    object\n",
            " 4   Cleaned_Text  100 non-null    object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 4.0+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "               Tweet_ID                  Username                 Created_At  \\\n",
              " 0  1891678317633315207  user_1891022278533709824  2025-02-18 02:37:11+00:00   \n",
              " 1  1891678309819301954  user_1849144255274713088  2025-02-18 02:37:09+00:00   \n",
              " 2  1891678288025718879  user_1422938193339420682  2025-02-18 02:37:04+00:00   \n",
              " 3  1891678273496662092  user_1748991548455563264  2025-02-18 02:37:00+00:00   \n",
              " 4  1891678257667318099  user_1517080755356065795  2025-02-18 02:36:56+00:00   \n",
              " \n",
              "                                                 Text  \\\n",
              " 0  @stellardeployer @Ashcryptoreal @pumpdotfun @f...   \n",
              " 1  Rain Girl \\n#雨水 #ai #aiart #aigirl #aiwomen #a...   \n",
              " 2  Abridge @AbridgeHQ Raises $250 Million in Seri...   \n",
              " 3             Bullish\\nAwesome\\n\\n@Ammo_AI #AI #ammo   \n",
              " 4  @Ammo_AI #AI #ammo \\nThis is a great project, ...   \n",
              " \n",
              "                                         Cleaned_Text  \n",
              " 0  we have all the elements to make this the next...  \n",
              " 1                                          Rain Girl  \n",
              " 2            Abridge  Raises 250 Million in Series D  \n",
              " 3                                   Bullish\\nAwesome  \n",
              " 4  This is a great project I hope the project dev...  )"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned DataFrame to a CSV file\n",
        "cleaned_file_path_tweeter = \"twitter_ai_ml_tweets_cleaned_final.csv\"\n",
        "df.to_csv(cleaned_file_path_tweeter, index=False)\n",
        "\n",
        "files.download(cleaned_file_path_tweeter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e0AqlNIJ7IiN",
        "outputId": "169bdc13-23d3-4910-e232-cdaa7409168f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa721c7f-f50b-400a-aa7c-ef9d325c9cec\", \"twitter_ai_ml_tweets_cleaned_final.csv\", 33500)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFPxJV1Z82ur"
      },
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All the questions were challenging for me. I found question 5 somewhat esay but rest of the question were diffcult to slove."
      ],
      "metadata": {
        "id": "GWMEAgUT7DVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85V9h9uc82ur"
      },
      "source": [
        "# Write your response below\n",
        "Fill out survey and provide your valuable feedback.\n",
        "\n",
        "https://docs.google.com/forms/d/e/1FAIpQLSd_ObuA3iNoL7Az_C-2NOfHodfKCfDzHZtGRfIker6WyZqTtA/viewform?usp=dialog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw7J9c5t82us"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}